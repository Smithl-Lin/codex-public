{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": [
    "# AMANI × MedGemma — Multilingual Medical Resource Routing\n",
    "\n",
    "**Kaggle AI in Medicine Hackathon 2026**\n",
    "\n",
    "This notebook demonstrates the full AMANI pipeline: a 5-layer AI architecture that routes complex international patients to appropriate clinical trials, regenerative medicine programs, and frontier medical technologies.\n",
    "\n",
    "**Powered by:** Google MedGemma 1.5 4B — a medically-specialized vision-language model trained on healthcare data.\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture Overview\n",
    "\n",
    "```\n",
    "Clinical Note (ZH/AR/TH/EN)\n",
    "        ↓\n",
    "  L1 Sentinel Gate    ← Entropy-based quality filter (D-value)\n",
    "        ↓\n",
    "  L2 MedGemma         ← Clinical parsing + urgency detection\n",
    "  L2 Trinity-Audit    ← 3-model consensus (MedGemma + GPT-4o + Claude)\n",
    "  L2 TrialMatching    ← Semantic keyword-overlap trial scoring\n",
    "  L2 AssetResolution  ← AGID registry lookup\n",
    "        ↓\n",
    "  L2.5 Value/TDLS     ← Total Disease Lifecycle Strategy + Shadow Quote\n",
    "        ↓\n",
    "  L3 Nexus Router     ← Global institution + travel routing\n",
    "        ↓\n",
    "  Structured Output   ← Trial match, cost, timeline, AGID\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Step 1 — Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# MedGemma requires HuggingFace access token (set HUGGING_FACE_HUB_TOKEN)\n",
    "# In mock mode (default), no GPU or token needed\n",
    "!pip install gradio>=4.0 transformers torch accelerate --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clone-header",
   "metadata": {},
   "source": [
    "## Step 2 — Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Clone the AMANI-MedGemma repository\n",
    "# Replace with your actual Kaggle/GitHub repo URL after submission\n",
    "# !git clone https://github.com/your-username/amani-medgemma.git\n",
    "# %cd amani-medgemma\n",
    "\n",
    "# For Kaggle: files are already in /kaggle/working/\n",
    "# Uncomment if running on Kaggle:\n",
    "# %cd /kaggle/working/amani-medgemma\n",
    "\n",
    "print('Repository ready. Running in:', os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env-header",
   "metadata": {},
   "source": [
    "## Step 3 — Configure Environment\n",
    "\n",
    "By default the pipeline runs in **mock mode** — deterministic demo outputs requiring no GPU or API keys.\n",
    "\n",
    "To use real MedGemma inference, set `AMANI_MOCK_MODE=false` and provide a HuggingFace token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "env-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# --- MODE SELECTION ---\n",
    "# 'true'  = Mock mode (fast, no GPU required, deterministic demo outputs)\n",
    "# 'false' = Real MedGemma 1.5 4B inference (requires GPU + HuggingFace token)\n",
    "os.environ['AMANI_MOCK_MODE'] = 'true'\n",
    "\n",
    "# Optional: set HuggingFace token for real inference\n",
    "# os.environ['HUGGING_FACE_HUB_TOKEN'] = 'hf_...'\n",
    "\n",
    "print(f\"Mock mode: {os.environ['AMANI_MOCK_MODE']}\")\n",
    "print(\"Pipeline configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-header",
   "metadata": {},
   "source": [
    "## Step 4 — Import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "\n",
    "# Add project root to path if needed\n",
    "# sys.path.insert(0, '/path/to/amani-medgemma')\n",
    "\n",
    "from app import run_full_pipeline\n",
    "\n",
    "print('AMANI pipeline imported successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "case-a-header",
   "metadata": {},
   "source": [
    "## Step 5 — Case A: Chinese NSCLC Patient (Mandarin)\n",
    "\n",
    "**Patient:** 52-year-old male, Non-Small Cell Lung Cancer Stage IIIB, EGFR L858R+, third-line failure. Seeking CAR-T or gene therapy clinical trial.\n",
    "\n",
    "**Input language:** Simplified Chinese (ZH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "case-a",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_a = \"患者男性，52岁，非小细胞肺癌IIIB期。EGFR L858R阳性。三线治疗后进展。寻求基因治疗或CAR-T临床试验。\"\n",
    "\n",
    "print(\"Processing Case A (ZH — NSCLC IIIB)...\")\n",
    "result_a = run_full_pipeline(note_a, 'case_a')\n",
    "\n",
    "# --- Display key outputs ---\n",
    "s = result_a.get('summary', {})\n",
    "L = result_a['layers']\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CASE A RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  D-value (precision):  {L['L1_Sentinel']['d_value']:.3f}\")\n",
    "print(f\"  Urgency:              {L['L2_MedGemma']['urgency']}\")\n",
    "print(f\"  Trinity consensus:    {L['L2_Trinity']['status']} → {L['L2_Trinity']['consensus_agid']}\")\n",
    "\n",
    "tm = L.get('L2_TrialMatching', {})\n",
    "if tm.get('top_matches'):\n",
    "    top = tm['top_matches'][0]\n",
    "    print(f\"  Top trial:            {top['nct_id']} (score={top['match_score']})\")\n",
    "    print(f\"  Institution:          {top['institution']}\")\n",
    "    print(f\"  Trial PI:             {top['pi']}\")\n",
    "\n",
    "tdls = L.get('L2_5_Value', {})\n",
    "print(f\"  Total pathway cost:   ${tdls.get('total_cost_usd', 0):,.0f}\")\n",
    "print(f\"  Total duration:       {tdls.get('total_duration_days', 0)} days\")\n",
    "\n",
    "nexus = L.get('L3_Nexus', {})\n",
    "print(f\"  Routing:              {nexus.get('routing_decision', 'N/A')}\")\n",
    "print(f\"  Destination:          {nexus.get('destination_country', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "case-b-header",
   "metadata": {},
   "source": [
    "## Step 6 — Case B: Saudi Stem Cell Patient (English/Arabic context)\n",
    "\n",
    "**Patient:** 68-year-old Saudi male, post-CABG 2019, stable CAD, bilateral knee OA Grade III. MoCA 26/30. Seeking comprehensive stem cell regenerative program in Japan.\n",
    "\n",
    "**Input language:** English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "case-b",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_b = (\"68-year-old Saudi male, post-CABG 2019, stable CAD, bilateral knee OA Grade III. \"\n",
    "           \"MoCA 26/30. Seeking comprehensive stem cell regenerative program in Japan.\")\n",
    "\n",
    "print(\"Processing Case B (EN — Stem Cell / Regenerative Medicine)...\")\n",
    "result_b = run_full_pipeline(note_b, 'case_b')\n",
    "\n",
    "L = result_b['layers']\n",
    "tm = L.get('L2_TrialMatching', {})\n",
    "tdls = L.get('L2_5_Value', {})\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CASE B RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  D-value (precision):  {L['L1_Sentinel']['d_value']:.3f}\")\n",
    "print(f\"  Urgency:              {L['L2_MedGemma']['urgency']} (elective → timeline ×1.3)\")\n",
    "print(f\"  Trinity consensus:    {L['L2_Trinity']['status']} → {L['L2_Trinity']['consensus_agid']}\")\n",
    "\n",
    "if tm.get('top_matches'):\n",
    "    top = tm['top_matches'][0]\n",
    "    print(f\"  Top trial:            {top['nct_id']} (score={top['match_score']})\")\n",
    "    print(f\"  Institution:          {top['institution']}\")\n",
    "\n",
    "print(f\"  Total pathway cost:   ${tdls.get('total_cost_usd', 0):,.0f}\")\n",
    "print(f\"  Total duration:       {tdls.get('total_duration_days', 0)} days (elective-extended)\")\n",
    "\n",
    "# TDLS stage breakdown\n",
    "print(f\"\\n  TDLS Stage Breakdown:\")\n",
    "for stage in tdls.get('stages', []):\n",
    "    print(f\"    Stage {stage['stage']}: {stage['title'][:45]:<45} ${stage['cost_usd']:>8,.0f}  {stage['duration_days']}d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "case-c-header",
   "metadata": {},
   "source": [
    "## Step 7 — Case C: Thai Parkinson's Patient (Thai language)\n",
    "\n",
    "**Patient:** 61-year-old Thai male, Parkinson's H&Y Stage 4, post bilateral STN-DBS 2022 (declining benefit). Seeking BCI clinical trial in the United States.\n",
    "\n",
    "**Input language:** Thai (TH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "case-c",
   "metadata": {},
   "outputs": [],
   "source": [
    "note_c = \"ผู้ป่วยชายไทย อายุ 61 ปี โรคพาร์กินสัน H&Y Stage 4 ได้รับการผ่าตัด DBS ปี 2022 ต้องการเข้าถึง BCI clinical trial ในสหรัฐอเมริกา\"\n",
    "\n",
    "print(\"Processing Case C (TH — Parkinson's BCI Trial)...\")\n",
    "result_c = run_full_pipeline(note_c, 'case_c')\n",
    "\n",
    "L = result_c['layers']\n",
    "tm = L.get('L2_TrialMatching', {})\n",
    "tdls = L.get('L2_5_Value', {})\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"CASE C RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  D-value (precision):  {L['L1_Sentinel']['d_value']:.3f}\")\n",
    "print(f\"  Urgency:              {L['L2_MedGemma']['urgency']}\")\n",
    "print(f\"  Trinity consensus:    {L['L2_Trinity']['status']} → {L['L2_Trinity']['consensus_agid']}\")\n",
    "print(f\"  Matches found:        {tm.get('matches_found', 0)}\")\n",
    "\n",
    "if tm.get('top_matches'):\n",
    "    for i, m in enumerate(tm['top_matches'][:2]):\n",
    "        print(f\"  Trial #{i+1}:             {m['nct_id']} (score={m['match_score']}) — {m['institution']}\")\n",
    "\n",
    "print(f\"  Total pathway cost:   ${tdls.get('total_cost_usd', 0):,.0f}\")\n",
    "print(f\"  Total duration:       {tdls.get('total_duration_days', 0)} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-header",
   "metadata": {},
   "source": [
    "## Step 8 — Cross-Case Comparison\n",
    "\n",
    "Demonstrating that the pipeline produces **differentiated, case-specific outputs** — not generic responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'='*70}\")\n",
    "print(f\"{'CROSS-CASE COMPARISON':^70}\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"{'Metric':<30} {'Case A (ZH/NSCLC)':<20} {'Case B (EN/StemCell)':<22} {'Case C (TH/PD)'}\")\n",
    "print(f\"{'-'*70}\")\n",
    "\n",
    "cases = [\n",
    "    ('result_a', result_a),\n",
    "    ('result_b', result_b),\n",
    "    ('result_c', result_c),\n",
    "]\n",
    "\n",
    "# Extract metrics\n",
    "metrics = {}\n",
    "for key, r in cases:\n",
    "    L = r['layers']\n",
    "    tm = L.get('L2_TrialMatching', {})\n",
    "    top_score = tm['top_matches'][0]['match_score'] if tm.get('top_matches') else 0\n",
    "    metrics[key] = {\n",
    "        'd_value': L['L1_Sentinel']['d_value'],\n",
    "        'urgency': L['L2_MedGemma']['urgency'],\n",
    "        'agid': L['L2_Trinity']['consensus_agid'],\n",
    "        'trial_score': top_score,\n",
    "        'cost': L.get('L2_5_Value', {}).get('total_cost_usd', 0),\n",
    "        'days': L.get('L2_5_Value', {}).get('total_duration_days', 0),\n",
    "    }\n",
    "\n",
    "rows = [\n",
    "    ('D-value', 'd_value', '{:.3f}'),\n",
    "    ('Urgency', 'urgency', '{}'),\n",
    "    ('Top AGID', 'agid', '{}'),\n",
    "    ('Trial score', 'trial_score', '{:.2f}'),\n",
    "    ('Cost (USD)', 'cost', '${:,.0f}'),\n",
    "    ('Duration (days)', 'days', '{}'),\n",
    "]\n",
    "\n",
    "for label, key, fmt in rows:\n",
    "    vals = [fmt.format(metrics[k][key]) for k in ['result_a', 'result_b', 'result_c']]\n",
    "    print(f\"{label:<30} {vals[0]:<20} {vals[1]:<22} {vals[2]}\")\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"\\nScore differentiation confirmed:\", \n",
    "      len(set(metrics[k]['trial_score'] for k in metrics)) >= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noise-header",
   "metadata": {},
   "source": [
    "## Step 9 — Noise Input Safety Test\n",
    "\n",
    "Demonstrating L1 Sentinel gate and Trinity SOFT_CONFLICT handling for non-medical queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noise-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_input = \"What is the weather today?\"\n",
    "\n",
    "print(\"Testing noise input handling...\")\n",
    "result_noise = run_full_pipeline(noise_input, 'auto')\n",
    "\n",
    "L = result_noise['layers']\n",
    "print(f\"\\n  Input:          '{noise_input}'\")\n",
    "print(f\"  L1 status:      {L['L1_Sentinel']['status']}\")\n",
    "print(f\"  Trinity status: {L.get('L2_Trinity', {}).get('status', 'N/A')}\")\n",
    "print(f\"  AGID:           {L.get('L2_Trinity', {}).get('consensus_agid', 'N/A')}\")\n",
    "print(f\"  Warning:        {result_noise.get('warning', 'None')}\")\n",
    "print(\"\\n  Graceful degradation confirmed — no crash, appropriate routing to HITL.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gradio-header",
   "metadata": {},
   "source": [
    "## Step 10 — Launch Gradio UI\n",
    "\n",
    "Interactive 4-tab interface for exploring all pipeline layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gradio-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app import build_gradio_app\n",
    "\n",
    "ui = build_gradio_app()\n",
    "\n",
    "# Launch the Gradio interface\n",
    "# share=True creates a public link (useful for Kaggle/Colab)\n",
    "ui.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "credits",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Architecture Credits\n",
    "\n",
    "| Component | Technology |\n",
    "|-----------|------------|\n",
    "| Medical AI core | Google MedGemma 1.5 4B (`google/medgemma-1.5-4b-it`) |\n",
    "| Trinity consensus | MedGemma + GPT-4o + Claude (3-model audit) |\n",
    "| UI framework | Gradio 4.x |\n",
    "| Trial database | Demo: NCT-06234517, NCT-06578901, NCT-06891023 |\n",
    "| AGID registry | AMANI Asset Graph ID system |\n",
    "| Languages | ZH / AR / TH / EN |\n",
    "\n",
    "**License:** Apache 2.0  \n",
    "**Submission:** Kaggle AI in Medicine Hackathon 2026  \n",
    "**Architecture:** AMANI Sovereign Medical Routing Protocol"
   ]
  }
 ]
}
