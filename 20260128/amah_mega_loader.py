import chromadb
import json
import random
import time
from chromadb.config import Settings

class AMAHMegaLoader:
    def __init__(self):
        # åˆå§‹åŒ–æŒä¹…åŒ–å­˜å‚¨
        self.client = chromadb.PersistentClient(path="./amah_vector_db")
        # é’ˆå¯¹å¤§è§„æ¨¡æ•°æ®è°ƒä¼˜ HNSW ç´¢å¼•
        self.collection = self.client.get_or_create_collection(
            name="expert_map_global",
            metadata={
                "hnsw:space": "cosine",
                "hnsw:construction_ef": 800,
                "hnsw:M": 64
            }
        )

    def generate_high_fidelity_batch(self, count):
        """ç”Ÿæˆå¤§è§„æ¨¡é«˜ç²¾ä¸“å®¶é•œåƒæ•°æ®"""
        hubs = ["Jacksonville", "Houston", "Boston", "Cleveland", "Palo Alto", "New York"]
        specialties = ["STN-DBS", "Focused-Ultrasound", "Neuro-Regeneration", "Gene-Therapy"]
        
        batch_data = []
        for i in range(count):
            hub = random.choice(hubs)
            spec = random.choice(specialties)
            expert = {
                "id": f"mega_exp_{i:06d}",
                "name": f"Dr. Elite_{hub}_{i}",
                "document": f"{hub} {spec} Precision Medicine Medicare Travel-Concierge latest clinical trials {spec}",
                "metadata": {
                    "hub": hub,
                    "specialty": spec,
                    "services": json.dumps(["Hospital-Docking", "Travel-Concierge"])
                }
            }
            batch_data.append(expert)
        return batch_data

    def execute_bulk_import(self, total_count, batch_size=500):
        """æ‰§è¡Œå¤§è§„æ¨¡åˆ†æ‰¹å¯¼å…¥"""
        print(f"ğŸš€ å¼€å§‹ç¡¬åŒ– {total_count} ä¸ªä¸“å®¶èŠ‚ç‚¹è‡³å‘é‡ç©ºé—´...")
        start_time = time.time()
        
        for i in range(0, total_count, batch_size):
            batch = self.generate_high_fidelity_batch(min(batch_size, total_count - i))
            
            self.collection.upsert(
                ids=[e["id"] for e in batch],
                documents=[e["document"] for e in batch],
                metadatas=[e["metadata"] for e in batch]
            )
            if i % 5000 == 0:
                print(f"âœ… å·²å®Œæˆ: {i}/{total_count}")
        
        print(f"ğŸ å¯¼å…¥å®Œæˆã€‚æ€»è€—æ—¶: {time.time() - start_time:.2f}s")

if __name__ == "__main__":
    loader = AMAHMegaLoader()
    # å…ˆæ³¨å…¥ 1000 ä¸ªé«˜ç²¾ç§å­èŠ‚ç‚¹ç”¨äºè·¯æ¼”å±•ç¤ºï¼ˆå¯æ ¹æ®éœ€è¦è°ƒæ•´ä¸º 100,000ï¼‰
    loader.execute_bulk_import(1000)
    print(f"\nğŸ“Œ å½“å‰åº“ä¸­æ€»èµ„äº§æ•°: {loader.collection.count()}")
