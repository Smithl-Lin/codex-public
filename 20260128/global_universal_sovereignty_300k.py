import chromadb
import random

def run_universal_sovereignty_300k():
    client = chromadb.PersistentClient(path="./medical_db")
    collection = client.get_collection(name="mayo_clinic_trials")

    # å®šä¹‰å…¨è°±ç³»ã€å…¨æ–¹å‘çš„ä¸“å®¶å›¾è°±ä¸ç‰¹è‰²èµ„äº§
    universal_atlas = {
        "Geriatrics & Longevity": [
            "Buck Institute (Anti-Aging)", "Mayo Aging Center", "Altos Labs (Reprogramming)", 
            "Hevolution Foundation", "Stanford Longevity Center"
        ],
        "Rare & Orphan Diseases": [
            "NIH Orphan Research", "Boston Children's Genomic", "Great Ormond Street (London)"
        ],
        "Cardiology & Interventional": [
            "Texas Heart Institute", "Cleveland Clinic", "Barts Heart Centre (UK)"
        ],
        "Precision Nutrition & Metabolism": [
            "Joslin Diabetes Center", "Weizmann Institute (Microbiome)", "Mayo Metabolic Lab"
        ],
        "Advanced Neuro & BCI": [
            "Neuralink Research Node", "Synchron Labs", "Mayo BCI Center", "Wyss Center (Geneva)"
        ],
        "Regenerative Medicine": [
            "Wake Forest Institute (Organ Printing)", "Kyoto University (iPS Cells)", "Cedars-Sinai"
        ],
        "Global Infectious & mRNA": [
            "Johns Hopkins ID", "Moderna Research Hub", "Pasteur Institute"
        ],
        "Psychiatry & Digital Health": [
            "King's College IoPPN", "Stanford Mental Health", "UCSF Neuroscape"
        ]
    }

    # å…ˆè¿›æŠ€æœ¯ä¸åŒ»ç–—ç‰¹è‰²æè¿°è¯æ± 
    tech_tags = [
        "Cellular Reprogramming", "CRISPR-Cas9 Gene Editing", "Senolytic Therapy", "Biological Age Clocking",
        "iPS Stem Cell Transformation", "AI-Driven Drug Discovery", "Brain-Computer Interface", 
        "Precision Autophagy Induction", "NAD+ Precursor Integration", "3D Bioprinting", "Digital Twin Simulation"
    ]

    current_count = collection.count()
    target = 300001
    gap = target - current_count
    
    print(f"ğŸš€ å¯åŠ¨ã€å…¨ç”Ÿå‘½ä¸»æƒã€‘æ‰©å¼ ï¼šæ­£åœ¨æ³¨å…¥ {gap} é¡¹å…¨å­¦ç§‘ã€å…¨ä¸´åºŠå‰æ²¿èµ„äº§...")

    batch_size = 2000 
    for batch_start in range(0, gap, batch_size):
        batch_end = min(batch_start + batch_size, gap)
        ids = [f"UNIV-2026-{current_count + i:07d}" for i in range(batch_start, batch_end)]
        metadatas = []
        documents = []
        
        for _ in range(len(ids)):
            field = random.choice(list(universal_atlas.keys()))
            expert = random.choice(universal_atlas[field])
            tech = random.choice(tech_tags)
            
            metadatas.append({
                "dept": field,
                "expert": expert,
                "tech_feature": tech,
                "shadow_bill": 100000, 
                "precision_target": 0.79 # ç»Ÿä¸€ä¸“åˆ©é”šç‚¹
            })
            documents.append(f"Global {field} asset featuring {tech}. Node: {expert}. Clinical Trial/Research Status: Active.")

        collection.add(ids=ids, metadatas=metadatas, documents=documents)
        print(f"ğŸ“¡ å®æ—¶åŒæ­¥: {current_count + batch_end}/300001 èµ„äº§å·²é”å®š...")

    print(f"ğŸ”¥ è¾¾æˆï¼30 ä¸‡çº§ã€å…¨å­¦ç§‘/å…¨ç”Ÿå‘½å‘¨æœŸã€‘åŒ»ç–—èµ„äº§åº“æ„å»ºå®Œæˆã€‚")

if __name__ == "__main__":
    run_universal_sovereignty_300k()