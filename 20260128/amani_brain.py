# V4.0_STRATEGIC_LOCKED_BY_SMITH_LIN
# -*- coding: utf-8 -*-
# ==============================================================================
# ğŸ§  A.M.A.N.I. TRINITY ENGINE (Version 4.0 - Strategic Lock)
# ==============================================================================
# Core Architecture:
#   1. Sentinel: E-CNN (Entropy-Weighted Convolutional Neural Network)
#   2. Brain:    Dynamic Logic Router (Geo/Lang/Ethnic Matrix)
#   3. Nexus:    GNN-Sim (Graph Neural Network Asset Anchoring)
# V4.0 Hardening: calculate_sliding_entropy æ³¢å½¢æ£€æµ‹ | variance>0.005 ç‰©ç†æ‹¦æˆª | AGID è¾“å‡ºä½“ç³»
# Patent Claims: No. 10 & 11 (Holographic Entropy & GNN Anchoring)
# ==============================================================================

import math
import collections
import hashlib
import numpy as np
import time

try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
except ImportError:
    print("âŒ ä¸¥é‡é”™è¯¯: ç¼ºå°‘æ·±åº¦å­¦ä¹ æ ¸å¿ƒåº“ PyTorchã€‚")
    print("   è¯·è¿è¡Œ: pip install torch torchvision")
    raise

# ------------------------------------------------------------------------------
# AGID ä½“ç³»ï¼šå…¨å±€èµ„äº§æ ‡è¯† (Asset Global ID)
# ------------------------------------------------------------------------------
def to_agid(namespace: str, node_type: str, raw_id) -> str:
    """å°†ä»»æ„è¾“å‡ºèŠ‚ç‚¹ç»Ÿä¸€é‡æ„ä¸º AGID ä½“ç³»ã€‚"""
    sid = hashlib.sha256(f"{namespace}:{node_type}:{raw_id}".encode()).hexdigest()[:12].upper()
    return f"AGID-{namespace}-{node_type}-{sid}"


# ==============================================================================
# ğŸ§© PART 1: å·¥å…·ç±» - å…¨æ¯ç†µçº¹ç†ä¸æ³¢å½¢æ£€æµ‹ (calculate_sliding_entropy)
# ==============================================================================
class EntropyUtils:
    @staticmethod
    def calculate_sliding_entropy(text, window_size=5):
        """
        è®¡ç®—æ–‡æœ¬çš„'ç†µçº¹ç†' (Entropy Texture) â€” æ³¢å½¢æ£€æµ‹æ ¸å¿ƒã€‚
        è¾“å‡ºéšæ—¶é—´å˜åŒ–çš„å¯†åº¦æ³¢å½¢ï¼Œç”¨äº V4.0 ç¡¬åŒ–æ£€æµ‹ã€‚
        """
        tokens = list(text)
        seq_len = len(tokens)
        entropy_seq = []

        if seq_len == 0:
            return torch.zeros(1, 1, 1), 0.0

        for i in range(seq_len):
            start = max(0, i - window_size // 2)
            end = min(seq_len, i + window_size // 2 + 1)
            window = tokens[start:end]
            counts = collections.Counter(window)
            ent = 0.0
            total = len(window)
            for count in counts.values():
                p = count / total
                ent -= p * math.log2(p) if p > 0 else 0
            entropy_seq.append(ent)

        tensor = torch.tensor(entropy_seq, dtype=torch.float32).unsqueeze(0).unsqueeze(2)
        variance = np.var(entropy_seq) if entropy_seq else 0.0
        return tensor, variance

    @staticmethod
    def variance_physical_intercept(variance: float, threshold: float = 0.005) -> bool:
        """V4.0 ç¡¬æ€§æŒ‡æ ‡ï¼švariance > 0.005 ç‰©ç†æ‹¦æˆªé€»è¾‘ã€‚"""
        return float(variance) > threshold


# ==============================================================================
# ğŸ›¡ï¸ PART 2: å“¨å…µ - E-CNN (Entropy-Weighted CNN)
# ==============================================================================
class ECNN_Sentinel(nn.Module):
    def __init__(self, vocab_size=5000, embed_dim=128, num_filters=64, kernel_sizes=[3, 4, 5]):
        super(ECNN_Sentinel, self).__init__()
        self.embedding = nn.Embedding(vocab_size, embed_dim)
        self.convs = nn.ModuleList([
            nn.Conv1d(in_channels=embed_dim + 1, out_channels=num_filters, kernel_size=k)
            for k in kernel_sizes
        ])
        self.dropout = nn.Dropout(0.5)
        self.fc = nn.Linear(len(kernel_sizes) * num_filters, 3)

    def forward(self, x_indices, entropy_seq):
        embeds = self.embedding(x_indices)
        combined = torch.cat((embeds, entropy_seq), dim=2)
        combined = combined.permute(0, 2, 1)
        conved = [F.relu(conv(combined)) for conv in self.convs]
        pooled = [F.adaptive_max_pool1d(conv, 1).squeeze(2) for conv in conved]
        cat = torch.cat(pooled, dim=1)
        cat = self.dropout(cat)
        logits = self.fc(cat)
        return F.softmax(logits, dim=1)


# ==============================================================================
# ğŸ”— PART 3: è§¦æ‰‹ - GNN Nexus (Asset Anchoring) â€” è¾“å‡º AGID
# ==============================================================================
class GNN_Nexus_Sim(nn.Module):
    def __init__(self, num_assets=200000, feature_dim=192):
        super(GNN_Nexus_Sim, self).__init__()
        self.asset_memory = nn.Parameter(torch.randn(100, feature_dim))
        self.query_proj = nn.Linear(192, feature_dim)

    def forward(self, intent_vector):
        query = self.query_proj(intent_vector)
        scores = torch.matmul(query, self.asset_memory.t())
        attention = F.softmax(scores, dim=1)
        best_asset_idx = torch.argmax(attention, dim=1)
        return best_asset_idx, attention


# ==============================================================================
# ğŸ§  PART 4: ä¸‰ä½ä¸€ä½“ä¸»è„‘ (The Trinity Brain) â€” AGID è¾“å‡º
# ==============================================================================
class AMANI_Brain:
    def __init__(self):
        print("ğŸ§  æ­£åœ¨åˆå§‹åŒ– A.M.A.N.I. Trinity Engine V4.0 (E-CNN + GNN + AGID)...")
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"   â†³ ç¡¬ä»¶åŠ é€Ÿ: {self.device}")

        self.sentinel = ECNN_Sentinel().to(self.device)
        self.nexus = GNN_Nexus_Sim().to(self.device)
        self.sentinel.eval()
        self.vocab = {"<PAD>": 0, "<UNK>": 1}
        self.VARIANCE_INTERCEPT_THRESHOLD = 0.005

    def _text_to_tensor(self, text):
        indices = [hash(c) % 5000 for c in text]
        return torch.tensor(indices, dtype=torch.long).unsqueeze(0).to(self.device)

    def process_request(self, text):
        print(f"\nğŸ“© [INPUT] æ¥æ”¶æŒ‡ä»¤: \"{text}\"")
        start_time = time.time()

        # 1. ç†µçº¹ç† + æ³¢å½¢æ£€æµ‹ (calculate_sliding_entropy)
        entropy_tensor, entropy_variance = EntropyUtils.calculate_sliding_entropy(text)
        entropy_tensor = entropy_tensor.to(self.device)
        avg_entropy = entropy_tensor.mean().item()
        print(f"   ğŸŒŠ å…¨æ¯ç†µåˆ†æ: å¹³å‡ç†µå€¼ {avg_entropy:.4f} | æ³¢å½¢æ–¹å·® {entropy_variance:.6f}")

        # 2. variance > 0.005 ç‰©ç†æ‹¦æˆª
        if EntropyUtils.variance_physical_intercept(entropy_variance, self.VARIANCE_INTERCEPT_THRESHOLD):
            agid_intercept = to_agid("MAYO", "INTERCEPT", f"var_{entropy_variance:.6f}")
            print(f"   ğŸš« ç‰©ç†æ‹¦æˆª: æ³¢å½¢æ–¹å·® {entropy_variance:.6f} > 0.005 | èŠ‚ç‚¹: {agid_intercept}")
            return agid_intercept

        # 3. å“¨å…µæ„ŸçŸ¥ (E-CNN Forward)
        x_indices = self._text_to_tensor(text)
        with torch.no_grad():
            routing_weights = self.sentinel(x_indices, entropy_tensor)

        w_ethnic, w_geo, w_lang = routing_weights[0].tolist()
        print(f"   ğŸ§  ç¥ç»ç½‘ç»œè·¯ç”±å†³ç­–: [æ—ç¾¤]{w_ethnic:.2f} [åŒºåŸŸ]{w_geo:.2f} [è¯­è¨€]{w_lang:.2f}")

        final_decision = ""
        l1_weight = 0.0

        if avg_entropy < 1.5 or w_geo > 0.5:
            print("   ğŸš¦ åˆ¤å®š: ç²¾ç¡®æŒ‡ä»¤ (Precise Command)")
            print("   ğŸ”— æ¿€æ´» GNN Nexus å±‚ï¼Œæ­£åœ¨é”šå®šç‰©ç†èµ„äº§...")
            dummy_intent = torch.randn(1, 192).to(self.device)
            asset_id, _ = self.nexus(dummy_intent)
            raw_node_id = 200000 + asset_id.item()
            agid_node = to_agid("MAYO", "NODE", raw_node_id)
            print(f"   ğŸ“ GNN é”å®šèŠ‚ç‚¹: {agid_node}")
            final_decision = agid_node
            l1_weight = 0.88
        else:
            print("   ğŸš¦ åˆ¤å®š: æ¨¡ç³Šç—‡çŠ¶ (Symptom/Chat)")
            final_decision = to_agid("MAYO", "MODE", "MIXED_EMPATHY")
            l1_weight = 0.60

        print(f"   âœ… æœ€ç»ˆ L1 æ¨ç†æƒé‡: {l1_weight} | è¾“å‡ºèŠ‚ç‚¹: {final_decision}")
        print(f"   â±ï¸ è€—æ—¶: {(time.time() - start_time)*1000:.2f} ms")
        return final_decision


if __name__ == "__main__":
    brain = AMANI_Brain()
    brain.process_request("åŒ»ç”Ÿï¼Œæˆ‘è§‰å¾—æœ€è¿‘æœ‰ç‚¹å¿ƒæ…Œï¼Œä¸çŸ¥é“æ˜¯ä¸æ˜¯ç†¬å¤œå¤ªå¤šäº†ã€‚")
    brain.process_request("å‡†å¤‡é˜‘å°¾åˆ‡é™¤æœ¯ï¼Œé™è„‰æ³¨å°„ä¸™æ³Šé…š20mgã€‚")
