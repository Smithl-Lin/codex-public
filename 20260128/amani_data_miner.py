import time
from Bio import Entrez
import json
import os

# ================= é…ç½®åŒº =================
Entrez.email = "smithlin_demo@google.com"  # ä¿æŒæ‚¨çš„é‚®ç®±è®¾ç½®
OUTPUT_DIR = "AMANI_Training_Data"
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

# ================= é¥±å’Œå¼æœç´¢ç­–ç•¥ =================
# é€»è¾‘å‡çº§ï¼šSEARCH_POOL è®¾å®šä¸º 5000ï¼Œç¡®ä¿å³ä½¿æŸè€—ç‡é«˜ï¼Œä¹Ÿèƒ½å‡‘æ»¡ target_count
TARGETS = [
    {
        "category": "Neuro_Degenerative",
        "target_count": 500, # å¿…é¡»å‡‘æ»¡çš„æ•°é‡
        "search_pool": 5000, # æœç´¢æ± æ·±åº¦
        "term": '("Multiple System Atrophy" OR "Amyotrophic Lateral Sclerosis" OR "Parkinson Disease" OR "Alzheimer Disease" OR "Progressive Supranuclear Palsy" OR "Dementia") AND "Case Reports"[pt] AND English[lang]'
    },
    {
        "category": "Oncology_Complex",
        "target_count": 300,
        "search_pool": 3000,
        "term": '("Brain Neoplasms" OR "Lung Neoplasms" OR "Liver Neoplasms" OR "Pancreatic Neoplasms" OR "Mutation") AND "Case Reports"[pt] AND English[lang]'
    },
    {
        "category": "Rare_Undiagnosed",
        "target_count": 200,
        "search_pool": 2000,
        "term": '("Rare Diseases" OR "Undiagnosed Diseases" OR "Diagnostic Errors") AND "Case Reports"[pt] AND English[lang]'
    },
    {
        "category": "Pediatric_Developmental",
        "target_count": 200,
        "search_pool": 2000,
        "term": '("Infant" OR "Child" OR "Developmental Disabilities" OR "Genetic Diseases, Inborn") AND "Case Reports"[pt] AND English[lang]'
    }
]

# ================= åŠŸèƒ½å‡½æ•° =================

def search_cases(term, max_ret_count):
    """è·å–å¤§é‡ ID ä½œä¸ºçŸ¿æ± """
    try:
        # ä½¿ç”¨ sort='date' è·å–æœ€æ–°çš„ç—…ä¾‹ï¼Œè´¨é‡é€šå¸¸æ›´é«˜
        handle = Entrez.esearch(db="pubmed", term=term, retmax=max_ret_count, sort="date")
        record = Entrez.read(handle)
        handle.close()
        return record["IdList"]
    except Exception as e:
        print(f"    [!] Search Error: {e}")
        return []

def fetch_and_filter(id_pool, target_needed, batch_size=50):
    """
    é¥±å’Œå¼ä¸‹è½½ï¼šç›´åˆ°å‡‘æ»¡ target_needed ä¸ºæ­¢
    """
    valid_articles = []
    total_scanned = 0
    
    # å¾ªç¯å¤„ç†çŸ¿æ± ä¸­çš„ ID
    for i in range(0, len(id_pool), batch_size):
        # æ£€æŸ¥æ˜¯å¦å·²ç»å‡‘å¤Ÿäº†
        if len(valid_articles) >= target_needed:
            break
            
        batch_ids = id_pool[i:i+batch_size]
        try:
            print(f"    -> Scanning batch {i}/{len(id_pool)} | Valid collected: {len(valid_articles)}/{target_needed}...")
            handle = Entrez.efetch(db="pubmed", id=batch_ids, retmode="xml")
            records = Entrez.read(handle)
            handle.close()
            
            if 'PubmedArticle' in records:
                for article in records['PubmedArticle']:
                    # å¦‚æœå·²ç»å¤Ÿäº†ï¼Œç›´æ¥é€€å‡ºå†…å±‚å¾ªç¯
                    if len(valid_articles) >= target_needed:
                        break
                        
                    try:
                        medline = article['MedlineCitation']
                        article_data = article['MedlineCitation']['Article']
                        
                        # ä¸¥æ ¼è¿‡æ»¤ï¼šå¿…é¡»æœ‰éç©ºçš„æ‘˜è¦
                        if 'Abstract' not in article_data or 'AbstractText' not in article_data['Abstract']:
                            continue
                            
                        abstract_text = article_data['Abstract']['AbstractText']
                        final_abstract = " ".join([str(x) for x in abstract_text]) if isinstance(abstract_text, list) else str(abstract_text)
                        
                        # äºŒæ¬¡è¿‡æ»¤ï¼šæ‘˜è¦é•¿åº¦å¤ªçŸ­çš„ä¸è¦ï¼ˆå¾€å¾€æ˜¯æ— æ•ˆä¿¡æ¯ï¼‰
                        if len(final_abstract) < 50:
                            continue

                        data = {
                            "pmid": str(medline['PMID']),
                            "title": article_data.get('ArticleTitle', ''),
                            "abstract": final_abstract,
                            "keywords": [str(kw) for kw in medline.get('KeywordList', [[]])[0]] if 'KeywordList' in medline else [],
                            "date": article_data.get('ArticleDate', [{}])[0].get('Year', '')
                        }
                        valid_articles.append(data)
                        
                    except Exception:
                        continue
            
            time.sleep(0.5) # é¿å…è¿‡å¿«
            
        except Exception as e:
            print(f"    [!] Batch Error: {e}")
            continue

    return valid_articles

# ================= ä¸»ç¨‹åº =================

def main():
    print("=== A.M.A.N.I. Data Miner V1.3 (Saturation Mode) ===")
    print("Strategy: Over-fetch IDs to guarantee target count.")
    print("---------------------------------------------")

    total_collected = 0

    for target in TARGETS:
        category = target["category"]
        goal = target["target_count"]
        print(f"\n>>> Starting Job: {category} (Target: {goal})")
        
        # 1. å»ºç«‹å·¨å¤§çš„ ID çŸ¿æ± 
        id_pool = search_cases(target["term"], target["search_pool"])
        print(f"    -> ID Pool created with {len(id_pool)} candidates.")
        
        if id_pool:
            # 2. é¥±å’Œå¼ä¸‹è½½
            data = fetch_and_filter(id_pool, goal)
            
            # 3. ä¿å­˜
            if data:
                filename = os.path.join(OUTPUT_DIR, f"{category}_training_set.json")
                with open(filename, 'w', encoding='utf-8') as f:
                    json.dump(data, f, indent=4, ensure_ascii=False)
                
                print(f"âœ… SUCCESS: Collected {len(data)}/{goal} cases for {category}")
                total_collected += len(data)
            else:
                print(f"âš ï¸ Warning: Scanned all IDs but found 0 valid abstracts.")
        else:
            print(f"âš ï¸ Error: Search returned 0 IDs.")

    print("\n=============================================")
    print(f"ğŸš€ Mission Complete. Total High-Quality Cases: {total_collected}")
    print(f"ğŸ“ Data location: {os.path.abspath(OUTPUT_DIR)}")
    print("=============================================")

if __name__ == "__main__":
    main()